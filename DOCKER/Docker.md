
# Docker 

## What is Docker?

Docker is an `open platform` for developing, shipping, and running applications. Docker enables you to `separate your applications from your infrastructure` so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker's methodologies for shipping, testing, and deploying code, you can significantly reduce the delay between writing code and running it in production.

## The Docker platform

Docker provides the ability to package and run an application in a loosely isolated environment called a container. The isolation and security lets you run many containers simultaneously on a given host. Containers are lightweight and contain everything needed to run the application, so you don't need to rely on what's installed on the host. You can share containers while you work, and be sure that everyone you share with gets the same container that works in the same way.

## What can I use Docker for?

### Fast, consistent delivery of your applications

Docker streamlines the development lifecycle by allowing developers to work in standardized environments using local containers which provide your applications and services. Containers are great for continuous integration and continuous delivery (CI/CD) workflows.


## Docker architecture

Docker uses a client-server architecture. The Docker client talks to the Docker daemon, which does the heavy lifting of building, running, and distributing your Docker containers. The Docker client and daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API, over UNIX sockets or a network interface. Another Docker client is Docker Compose, that lets you work with applications consisting of a set of containers.

### The Docker daemon

The Docker daemon (`dockerd`) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. A daemon can also communicate with other daemons to manage Docker services.

### The Docker client

The Docker client (`docker`) is the primary way that many Docker users interact with Docker. When you use commands such as `docker run`, the client sends these commands to `dockerd`, which carries them out. The `docker` command uses the Docker API. The Docker client can communicate with more than one daemon.

### Docker Desktop

Docker Desktop is an easy-to-install application for your Mac, Windows or Linux environment that enables you to build and share containerized applications and microservices. Docker Desktop includes the Docker daemon (`dockerd`), the Docker client (`docker`), Docker Compose, Docker Content Trust, Kubernetes, and Credential Helper. For more information, see Docker Desktop.

### Docker registries

A Docker registry stores Docker images. Docker Hub is a public registry that anyone can use, and Docker looks for images on Docker Hub by default. You can even run your own private registry.

When you use the `docker pull` or `docker run` commands, Docker pulls the required images from your configured registry. When you use the `docker push` command, Docker pushes your image to your configured registry.

### Docker objects
When you use Docker, you are creating and using images, containers, networks, volumes, plugins, and other objects. This section is a brief overview of some of those objects.

### Images
An image is a read-only template with instructions for creating a Docker container. Often, an image is based on another image, with some additional customization. For example, you may build an image which is based on the `ubuntu` image, but installs the Apache web server and your application, as well as the configuration details needed to make your application run.

You might create your own images or you might only use those created by others and published in a registry. To build your own image, you create a Dockerfile with a simple syntax for defining the steps needed to create the image and run it. Each instruction in a Dockerfile creates a layer in the image. When you change the Dockerfile and rebuild the image, only those layers which have changed are rebuilt. This is part of what makes images so lightweight, small, and fast, when compared to other virtualization technologies.

### Containers
A container is a runnable instance of an image. You can create, start, stop, move, or delete a container using the Docker API or CLI. You can connect a container to one or more networks, attach storage to it, or even create a new image based on its current state.

By default, a container is relatively well isolated from other containers and its host machine. You can control how isolated a container's network, storage, or other underlying subsystems are from other containers or from the host machine.

A container is defined by its image as well as any configuration options you provide to it when you create or start it. When a container is removed, any changes to its state that aren't stored in persistent storage disappear.

## Problem & Why Docker

### Problem

Without Docker, you might run into several issues:

1. **Inconsistent Environments**:  
   Code might work on one machine but fail on another due to differences in libraries, dependencies, or system settings. Docker ensures consistency across different environments.

2. **Dependency Conflicts**:  
   Managing dependencies manually can lead to conflicts. Different applications might require different versions of the same library, leading to incompatibility issues.

3. **Complex Setup**:  
   Setting up environments manually can be time-consuming and error-prone. Docker simplifies this by encapsulating all dependencies within a container.

4. **Scalability Issues**:  
   Scaling applications without Docker can be challenging. Docker allows you to run multiple containers easily, enabling horizontal scaling.

5. **Resource Inefficiency**:  
   Running applications directly on the host system without isolation can lead to resource contention and inefficiency. Docker containers share the host system’s kernel, making them more resource-efficient.

### Examples

- **New Developer Onboarding**:  
  A new developer joining a company may need to install a wide variety of requirements or dependencies.  
  For example, a project might need the following stack:
  - **Backend**: PHP, Laravel, PostgreSQL, PostGIS, and Redis.
  - **Frontend**: JavaScript and Angular 4.

  Common issues like **installation errors** or the need to **downgrade versions** can occur. Docker simplifies this process.

- **Deploy Your App**:  
  Docker ensures that the same environment is used across **testing**, **staging**, and **production**, ensuring that no surprises arise when deploying your app.

---

## What & Why Docker?

Docker is a platform that allows developers to package applications into **containers**. Containers are lightweight, standalone packages that contain everything needed to run an application, including the **code**, **runtime**, **libraries**, and **system settings**.

### Key Benefits of Docker:

1. **Consistency Across Environments**:  
   Docker containers run the same way on any environment—whether it’s a developer's laptop, a test environment, or a production server. This consistency eliminates the "it works on my machine" problem.

2. **Isolation**:  
   Containers are isolated from each other and the host system. This ensures applications run in a predictable manner without interfering with other applications.

3. **Resource Efficiency**:  
   Containers share the host system's kernel and are more lightweight than virtual machines, which require a full operating system. This makes them more resource-efficient.

4. **Portability**:  
   Docker containers can be easily moved between different environments, making it simple to deploy applications across various systems without compatibility issues.

5. **Scalability**:  
   Docker makes it easy to scale applications by running multiple containers on a single host or across multiple hosts.

6. **Development & Deployment**:  
   Docker simplifies the development, testing, and deployment process by providing a consistent environment for all stages of the software development lifecycle.

---

## How to Install Docker

To install Docker on your system, follow the official Docker installation guides:

- **[Install Docker for Windows](https://docs.docker.com/desktop/install/windows-install/)**
- **[Install Docker for macOS](https://docs.docker.com/desktop/install/mac-install/)**
- **[Install Docker for Linux](https://docs.docker.com/engine/install/)**

---

## Dockerfile Example (Node.js Project)

This file contains instructions to build a Docker image. For instance, it specifies the base image, environment setup, application dependencies, and the command to run the application.

```dockerfile
# Use the specified Node.js version
FROM node:14  # Sets the base image to Node.js version 14

# Set the working directory inside the container
WORKDIR /app  # Defines /app as the working directory

# Copy package.json to the working directory
COPY package.json .  # Copies package.json to the working directory

# Install dependencies from package.json
RUN npm install  # Runs npm install to install dependencies

# Copy the rest of the project files to the working directory
COPY . .  # Copies all files from the current directory to the working directory in the container

# Expose port 4000 for external communication
EXPOSE 4000  # Specifies that the container listens on port 4000

# Define the command to run the application
CMD ["npm", "start"]  # Runs npm start to start the application
```

---

## Docker Hub

**Docker Hub** is a cloud-based repository for storing, managing, and sharing container images. It is the world’s largest container registry and simplifies the process of developing, distributing, and deploying containerized applications.

### Key Features of Docker Hub:

1. **Image Repository**:  
   Docker Hub hosts a vast collection of container images that you can use as a base for your projects.

2. **Public & Private Repositories**:  
   You can create public repositories to share your images with the community or private repositories to share with your team securely.

3. **Automated Builds**:  
   Docker Hub can automatically build images from a Dockerfile and push them to the repository.

4. **Collaboration**:  
   It allows teams to collaborate on container images, making it easier to manage and distribute applications.

5. **Pre-built Images**:  
   Docker Hub provides a wide range of pre-built images for popular software, which can speed up your development process.

---

## Build the Docker Image

Use the Dockerfile to create a Docker image with the following command:

```bash
docker build -t my-node-app .
```

- `-t my-node-app`: Tags the image with the name `my-node-app`.
- `.`: Specifies the current directory as the build context.

---

## Run Docker Containers

Once you have the image, you can create multiple containers from it. Each container runs as an isolated instance of the application.

1. **Run the first container**:
    ```bash
    docker run -d --name container1 -p 4001:4000 my-node-app
    ```
    This runs the container in detached mode, mapping port `4001` on the host to port `4000` in the container.

2. **Run the second container**:
    ```bash
    docker run -d --name container2 -p 4002:4000 my-node-app
    ```

---

## Docker Optimization

### Do I Need to Copy All Files?

No, you don’t need to copy all files. Using a `.dockerignore` file helps exclude unnecessary files and directories from the build context. This can speed up the build process and reduce the image size.

Example `.dockerignore`:

```plaintext
/node_modules
Dockerfile
.env
```

This ensures Docker does not include these files during the build.

---

### Why Did We Split the `package.json` Copy Command?

Splitting the `COPY` command into two parts is a common optimization strategy. By copying `package.json` first and running `npm install` before copying the rest of the files, Docker can cache the layers more efficiently. Here’s why:

- If only `package.json` and `package-lock.json` have changed, Docker can reuse the cached layers for installing dependencies, making the build process faster.
- If we copy all files first and then run `npm install`, any change in your source files will cause Docker to rerun the `npm install` step, which can be time-consuming.

---

By using Docker, you can streamline development, eliminate inconsistencies, and easily scale your applications, all while improving resource efficiency.

